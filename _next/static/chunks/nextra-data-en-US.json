{"/api-reference/channel-api":{"title":"API Reference: Channel","data":{"":"The Channel API is at the heart of SP8D: It gives you explicit, lock-free, slot-driven control over cross-thread messaging—plus direct access to real-time diagnostics, segmentation, and backpressure handling.","channel-creation#Channel Creation":"Create a channel for real-time, lock-free messaging. Use\ncreateChannel for new channels, attachChannel to\nconnect in another thread.","createchanneloptions--channel-buffer-#createChannel(options): { channel, buffer }":"Creates a new SP8D channel, returning both the API object and the underlying SharedArrayBuffer.Options:\nslots (number, required) — Number of slots in the ring buffer.\nslotSize (number, required) — Max size (bytes) per payload.\nmode (string: \"SPSC\" | \"MPSC\" | \"MPMC\", optional) — Concurrency mode. Default: \"SPSC\".\nsegments (number) — Segments for increased scale. Default: 1.\nsweepTimeoutMs (number) — Slot reclaim timeout (ms). Default: 50.\nconst { channel, buffer } = createChannel({\n  slots: 16,\n  slotSize: 64,\n  mode: \"MPMC\",\n  segments: 2,\n});","attachchannelbuffer-sharedarraybuffer-channel#attachChannel(buffer: SharedArrayBuffer): Channel":"","use-in-a-second-threadworker-to-attach-to-an-existing-channels-buffer#Use in a second thread/worker to attach to an existing channel’s buffer.":"// In a worker thread/process\nconst channel = attachChannel(buffer);","channel-api-core-methods#Channel API: Core Methods":"Methods are grouped by intent. Each group starts with a short intro and best\npractices. Scan, deep-dive, or jump to what you need.","send-data#Send Data":"Use trySend in high-frequency or non-critical paths to avoid\nexceptions. Use send when you must guarantee delivery or want to\ncatch errors.","sendpayload-arraybufferview-producerid-number-boolean#send(payload: ArrayBufferView, producerId?: number): boolean":"Enqueue a message. Throws if full or payload too large. Use for critical, must-succeed sends.","trysendpayload-arraybufferview-producerid-number-boolean#trySend(payload: ArrayBufferView, producerId?: number): boolean":"Enqueue a message. Returns false if full or payload too large—never throws. Use for non-blocking, best-effort sends.","sendasyncpayload-arraybufferview-producerid-number-opts-promiseboolean#sendAsync(payload: ArrayBufferView, producerId?: number, opts?): Promise<boolean>":"Waits for a slot and sends. Supports timeout and abort. Use for async, backpressure-aware flows.\nawait channel.sendAsync(msg, myProducerId, { timeoutMs: 1000 });","receive-data#Receive Data":"Use recvAsync for event-driven flows, and tryRecv\nfor polling or non-blocking loops.","recv-uint8array--null#recv(): Uint8Array | null":"Synchronous receive. Returns null if empty. Use for polling or tight loops.\nconst next = channel.recv();\nif (next) process(next);","tryrecv-uint8array--null#tryRecv(): Uint8Array | null":"Non-throwing, non-blocking receive. Returns null if empty.\nconst msg = channel.tryRecv();\nif (msg) process(msg);","recvasync-promiseuint8array--null#recvAsync(): Promise<Uint8Array | null>":"Async receive. Waits for a message. Use for event-driven or awaitable flows.\nconst msg = await channel.recvAsync();","json-helpers#JSON Helpers":"JSON helpers are for quick prototyping. For production, prefer binary\nserialization for performance and size.","sendjsonobj-object-producerid-number-boolean#sendJSON(obj: object, producerId?: number): boolean":"Send a JSON-serializable object. Throws if full or payload too large.","recvjson-object--null#recvJSON(): object | null":"Receive a JSON-serialized object. Returns null if empty or parse fails.","channel-state#Channel State":"Use full() and empty() to check channel status\nbefore sending or receiving in tight loops.","full-boolean#full(): boolean":"Returns true if the channel is full (no slots available for sending).","empty-boolean#empty(): boolean":"Returns true if the channel is empty (no slots available for reading).","lifecycle--control#Lifecycle & Control":"After close(), all send/recv methods will throw or return falsy.\nUse closeAsync for graceful shutdowns in async environments.","close-void#close(): void":"Immediately closes the channel and all internal timers. Cleans up, resets all state. After close(), send/recv throw or return falsy.","closeasync-promisevoid#closeAsync(): Promise<void>":"Gracefully closes the channel and waits for all background tasks to stop.\nawait channel.closeAsync();","reset-void#reset(): void":"Resets the channel to its initial state (empties all slots, resets counters). Does not reallocate the buffer.\nchannel.reset();","diagnostics--introspection#Diagnostics & Introspection":"Use stats() and info() for live monitoring and\ndebugging. Use validate() in tests to catch protocol errors\nearly.\nThe channel can be used as an async iterator for idiomatic, event-driven\nmessage consumption.","stats-channelstats#stats(): ChannelStats":"Returns a snapshot object of channel usage and health metrics.\nslots — total slots\nused — slots in use\nfree — slots available\nerrors, conflicts, reclaimed — counts of errors, producer/consumer collisions, and recovery sweeps","info-string#info(): string":"Returns a human-readable string of the channel’s configuration (mode, size, segments).","validate-void#validate(): void":"Checks protocol invariants—throws if any slot is in an illegal state. Use in development/testing, not hot production loops.","symbolasynciterator-asynciteratoruint8array-void#[Symbol.asyncIterator](): AsyncIterator<Uint8Array, void>":"The channel can be used as an async iterator:\nfor await (const msg of channel) {\n  // receive messages until channel.close()\n}","advanced-slot-status-internals#Advanced: Slot Status Internals":"For dashboards, monitoring, or debugging, access per-slot state directly.\nslotStatus (readonly Uint8Array[]) — current state for all slots\nslotClaimTimestamp (readonly Uint32Array[]) — last claimed timestamp per slot\nHow to use for live dashboards →","diagnostics--observability#Diagnostics & Observability":"Use diagnostics in development and staging to catch protocol issues early.\nAvoid running diagnostics in hot production loops unless you need live\nmonitoring.\nimport { createChannelDiagnostics } from \"@sp8d/diagnostics\";\nconst diagnostics = createChannelDiagnostics(channel, 100);\ndiagnostics.onUpdate((stats) => {\n  console.log(\"SP8D Stats:\", stats);\n});\ndiagnostics.start();\nSee the Diagnostics Guide → for more.","troubleshooting#Troubleshooting":"Most issues stem from mismatched buffer sizes, incorrect slot counts, or using\nthe wrong concurrency mode. Double-check your channel creation options.\nCommon issues are listed below. If you encounter persistent problems,\ndouble-check your channel configuration and concurrency mode.","common-issues--solutions#Common Issues & Solutions":"Problem: send or trySend always returns false or throws.\nSolution: Ensure the channel is not full. Check slotSize and payload size. For async flows, use sendAsync with a timeout.\nProblem: recv/tryRecv always returns null.\nSolution: The channel is empty. Confirm that producers are sending data and that you are not reading faster than writing.\nProblem: attachChannel throws or returns an unusable channel.\nSolution: Make sure the SharedArrayBuffer is valid and matches the expected structure (slots, slotSize, segments).\nProblem: Diagnostics report protocol errors or slot conflicts.\nSolution: Check that all threads use the correct concurrency mode (SPSC, MPSC, MPMC) and that no two producers/consumers are racing in SPSC mode.\nProblem: Channel appears to hang or deadlock.\nSolution: Avoid blocking the main thread. Use async methods and ensure all consumers/producers are running. For MPMC, ensure all parties are using unique IDs if required.","performance--concurrency-tips#Performance & Concurrency Tips":"For maximum throughput, tune slots and slotSize to\nmatch your message rate and payload size. Use the minimal number of segments\nneeded for your concurrency model.\nPrefer trySend/tryRecv in tight loops to avoid blocking.\nUse sendAsync/recvAsync for backpressure-aware, event-driven flows.\nIn high-concurrency scenarios, use the correct mode (MPSC or MPMC) and avoid sharing producer/consumer IDs.\nMonitor diagnostics in staging to catch contention or reclaim issues before production.\nAvoid frequent reset() in production; use it for test harnesses or controlled recovery only.\nFor lowest latency, keep sweepTimeoutMs low, but not zero—test for your workload.","related--next#Related / Next":"Explore diagnostics, concurrency patterns, and usage recipes to deepen your\nunderstanding and optimize your implementation.\nChannel diagnostics & live overlays →\nConcurrency patterns and modes →\nCommon usage recipes →\nFile an issue or contribute →"}},"/examples/basic-spsc":{"title":"Examples: Basic SPSC","data":{"":"The classic “lock-free queue” pattern—one producer, one consumer, highest throughput, zero overhead. SPSC is the fastest possible channel mode: no locks, no contention, and cache-friendly.\nSPSC (Single-Producer, Single-Consumer) channels are the gold standard for\nultra-low-latency, lock-free communication between exactly two threads or\ntasks. Use this pattern when you need maximum throughput and absolute\nordering, with zero contention or ambiguity.","minimal-spsc-example-nodejs-or-browser#Minimal SPSC Example (Node.js or Browser)":"This example walks you through the simplest SPSC channel: one producer, one\nconsumer, zero contention. Perfect for ultra-low-latency pipelines or thread\nhandoff. The diagram below shows the data flow.\nProducer uses send() to move data to the\nchannel. Consumer uses recv() to receive it.\nThis direct handoff is what enables SPSC's ultra-low latency and simplicity.\nimport { createChannel } from \"@sp8d/core\";\n// Create an SPSC channel with 4 slots, each slot holding up to 16 bytes.\nconst { channel } = createChannel({ slots: 4, slotSize: 16, mode: \"SPSC\" });\n// Producer sends messages\nfor (let i = 0; i < 8; ++i) {\n  // Wait if channel is full (backpressure)\n  while (!channel.send(new Uint8Array([i, i * 10]))) {\n    // Buffer is full, so producer waits and retries (busy-wait)\n  }\n  console.log(\"Sent:\", i);\n}\n// Consumer receives messages\nlet received: Uint8Array | null;\nwhile ((received = channel.recv()) !== null) {\n  console.log(\"Received:\", received);\n}\nThe busy-wait loop (while (!send)) is for demonstration only. In\nproduction, use sendAsync() or a backpressure-aware event loop to\navoid wasting CPU cycles.","asyncreal-world-example#Async/Real-World Example":"For real-world, non-blocking usage, use sendAsync() and the async\niterator as shown below.\n// Producer (async)\nfor (let i = 0; i < 8; ++i) {\n  await channel.sendAsync(new Uint8Array([i, i * 10]));\n  console.log(\"Sent:\", i);\n}\n// Consumer (async)\nfor await (const received of channel) {\n  console.log(\"Received:\", received);\n}","whats-happening#What's happening?":"Producer: Calls send() in a loop—respects backpressure if the buffer is full.\nConsumer: Calls recv() repeatedly—gets every value, in order, with no races or drops.\nSPSC Mode Guarantee: Guarantees simple “ping-pong” correctness: no overwrites, slot loss, or ambiguity.\nBackpressure is critical for lossless, high-throughput systems. Notice the\nproducer waits (while (!send)) if the ring is full. This ensures\nyou never lose data—even under burst conditions.\nThe output below shows the expected send/receive order for this example. If\nyou run producer and consumer in separate threads, the interleaving may\ndiffer, but all messages will be delivered in order.\nSent: 0\nSent: 1\nSent: 2\nSent: 3\nReceived: Uint8Array([0, 0])\nReceived: Uint8Array([1, 10])\nReceived: Uint8Array([2, 20])\nReceived: Uint8Array([3, 30])\nSent: 4\nSent: 5\nSent: 6\nSent: 7\nReceived: Uint8Array([4, 40])\nReceived: Uint8Array([5, 50])\nReceived: Uint8Array([6, 60])\nReceived: Uint8Array([7, 70])\nsend() returns false when full; always check for\nbackpressure.\nrecv() returns null when channel is empty.\nFor browser use, producer and consumer may be in separate threads—see\nbrowser recipes.\nFor async use, see recvAsync() or the async iterator.\nIf you see dropped messages, check your slot count and backpressure\nhandling.\nFor debugging, use diagnostics or enable verbose logging.\nSPSC is the fastest mode, but only if you stick to the\nsingle-producer/single-consumer contract. If you break this contract, you may\nsee data loss or protocol errors—use MPSC/MPMC for more complex patterns.","next--related#Next / Related":"Common usage recipes →\nFile an issue or contribute →"}},"/guides-and-howtos/faqs":{"title":"Frequently Asked Questions","data":{"sharedarraybuffer--browser-support#SharedArrayBuffer & Browser Support":"Q: Why do I get “Cannot use SharedArrayBuffer” or see errors about browser support?\nA: Your browser or environment may lack SharedArrayBuffer/Atomics support, or you may need special headers (COOP/COEP). See installation requirements.","diagnostics--live-monitoring#Diagnostics & Live Monitoring":"Q: How do I use diagnostics or monitor channel health?\nA: Use createChannelDiagnostics for live stats and monitoring. See the API reference for details.","backpressure--buffer-full#Backpressure & Buffer Full":"Q: What should I do if the channel is full or backpressured?\nA: Use sendAsync() or handle retries. See code examples for patterns.","protocol-errors--debugging#Protocol Errors & Debugging":"Q: What do protocol errors or slot conflicts mean?\nA: They usually indicate concurrency mode mismatch or incorrect usage. Double-check your channel setup.","async-iteration--patterns#Async Iteration & Patterns":"Q: Can I use async iteration with channels?\nA: Yes, channels support async iteration for event-driven consumption.","broadcasting--mpmc#Broadcasting & MPMC":"Q: How do I broadcast or use MPMC patterns?\nA: Use MPMC mode for multi-producer/multi-consumer. See concurrency models for details.","general#General":"Q: Still stuck or have another question?\nA: Open an issue or check the docs for more details."}},"/":{"title":"Start Here: Product Philosophy & Overview","data":{"":"The world’s first radically observable, lock-free, bounded protocol for cross-thread communication in browsers — designed for next-generation AI copilots, trading platforms, and multi-agent applications.","what-is-sp8d#What is SP8D?":"The world’s first radically observable, lock-free, bounded protocol for\ncross-thread communication in browsers — designed for next-generation AI\ncopilots, trading platforms, and multi-agent applications.\nSP8D is a breakthrough communication core for demanding front-end and AI workloads:\nBlazing-fast, lock-free, slot-based communication via SharedArrayBuffer and atomics\nTruly bounded and backpressure-driven, with guaranteed “never drop, never leak, never stall”\nBattle-tested for real-time trading, ML agents, and browser-native concurrency\nRadically observable: live diagnostics, transparency, and no more guessing why your system slowed down\nWhether you’re wiring up AI copilots, streaming market data, or building the next layer of browser-native intelligence—SP8D gives you tools, proof, and performance the rest of the ecosystem can’t match.","instant-hello-world-browsernode#Instant Hello World (Browser/Node)":"Try SP8D instantly in your browser or Node.js with this minimal example.\nimport { createChannel } from \"@sp8d/core\";\nconst { channel } = createChannel({ slots: 8, slotSize: 64 }); // SPSC mode by default\n// Producer\nchannel.send(new Uint8Array([1, 2, 3]));\n// Consumer\nconst msg: Uint8Array | undefined = channel.recv(); // Uint8Array([1, 2, 3])\nconsole.log(msg);\n→ See Quickstart for drop-in examples in\nBrowser Workers.","why-sp8d#Why SP8D?":"Tired of slow, memory-leaky, or debugging-nightmare message passing?\nNeed guaranteed low-latency, fairness, and traceability under stress?\nBuilding for regulated, high-stakes domains (finance, AI/ML, ops, browser concurrency)?\nSP8D is designed for you.","where-to-go-next#Where to Go Next":"Quickstart Guide: Install, run and win in 5 minutes\nMinimal Working Example: Copy, paste, and run instantly\nCore API Reference: Every method, every prop explained\nConcurrency Models: SPSC, MPSC, MPMC at a glance\nFAQ & Troubleshooting: “Why isn’t my message arriving?” and more\nLive Diagnostics & Benchmarking: Benchmark and observe SP8D live in your production environment\nReal-World Use Cases & Testimonials: SP8D in action (TODO)","architecture-at-a-glance#Architecture at a Glance":"For live observability, add @sp8d/diagnostics to any channel.","get-involved-#Get Involved 👋":"Found a bug? Ideas to expand? Want to sponsor SP8D adoption in your stack?\nContribute or open issues — all feedback and help welcome.\nWant to see the roadmap? Check our vision."}},"/introduction/what-is-sp8d":{"title":"Introduction: What is SP8D?","data":{"":"SP8D is a high-performance protocol for moving data instantly, reliably, and observably between concurrent agents in the browser or Node.js. Built for real-time web, AI, and finance, it solves the hardest concurrency problems—without compromise.\nStandard browser messaging APIs like postMessage and\nMessageChannel suffer from unpredictable latency, missed updates,\nand poor debuggability. SP8D is designed to solve these pain points for\ndemanding, real-time applications.","why-not-just-use-postmessage-or-messagechannel#Why Not Just Use postMessage or MessageChannel?":"Slow and unpredictable latency\nOpaque: hard to debug and reason about\nMissed updates and lost messages\nDebugging nightmares","what-makes-sp8d-different#What Makes SP8D Different?":"SP8D offers lock-free, slot-based concurrency, bounded memory, live\ndiagnostics, and built-in recovery—making it uniquely suited for high-stakes,\nreal-time, and multi-agent applications.\nLock-Free, Slot-Based Protocol: Uses atomic operations for true parallelism—no server roundtrips, no event-loop blocking, no lock contention.\nBounded and Predictable: Always a fixed memory footprint, explicit backpressure—no risk of memory leaks or runaway processes.\nSegmented and Scalable: Architected for many producers/consumers, scales linearly with your workload.\nRadically Observable: Live diagnostics for every slot, segment, and operation—see conflicts, errors, and lag in real time.\nBattle-Tested Recovery: Built-in recovery (sweeper) mechanism—survives thread death, browser hiccups, and adversarial loads.\nAI-First and Finance-Ready: Designed for demanding real-time and multi-agent flows, with specific integration points for AI, ML, and analytics.","who-is-sp8d-for#Who Is SP8D For?":"AI Developers: Need agent-to-agent or copilot collaboration, without postMessage pain.\nFintech Engineers: Building ultra-low-latency trading, analytics, or compliance-sensitive UIs.\nWeb Performance Experts: Who know why browser threads are a bottleneck, and want to break free.\nTeams moving past MVP: Where growth, reliability, and observability now matter as much as speed.","when-not-to-use-sp8d#When Not to Use SP8D":"SP8D is not ideal for unbounded message queues, trivial fire-and-forget comms,\nor environments lacking SharedArrayBuffer and\nAtomics support (very old browsers, strict CSP).\nYour app requires unbounded message queues or trivial best-effort “fire and forget” comms.\nYou only have a single event producer and consumer and never expect contention.\nBrowser SharedArrayBuffer and Atomics are not supported (very old browsers, highly restricted CSP).","architecture-at-a-glance#Architecture at a Glance":"SP8D channels use lock-free, slot-based buffers with live diagnostics,\nsupporting multiple producers and consumers for real-time, observable data\nflow.\nSP8D enables multiple producers and consumers to communicate through a\nlock-free, observable channel with live diagnostics.","sp8d-vs-postmessage-messagechannel-and-broadcastchannel#SP8D vs. postMessage, MessageChannel, and BroadcastChannel":"See how SP8D compares to standard browser messaging APIs in terms of\nperformance, reliability, and observability.\nHere’s how SP8D stacks up against common browser messaging APIs:\nFeature\tpostMessage\tMessageChannel\tBroadcastChannel\tSP8D\tLock-free\t❌\t❌\t❌\t✅\tBounded/Backpressure\t❌\t❌\t❌\t✅\tObservable/Diagnostics\t❌\t❌\t❌\t✅\tPredictable Latency\t❌\t❌\t❌\t✅\tMulti-producer/consumer\t🚫 (complex)\t🚫 (complex)\t✅\t✅\t\n❌ = Not supported, 🚫 = Possible but complex","how-it-works#How It Works":"Producers send data to the channel, which relays messages to consumers and\nemits live diagnostics for observability.\nSP8D channels enable real-time, observable data flow between producers and\nconsumers.\n💡 Lock-Free: No thread contention, ever.\n🛡️ Bounded: Never leaks, never stalls.\n🔍 Observable: See every event, live.\nLock-free, wait-free slot arbitration (no bottlenecks)\nFast, safe, observable reclamation (never stuck)\nSegment sharding for scalable concurrency\nFine-grained error, state, and performance tracking (radical observability)\nMax compatibility: Browser (WebWorker), Node.js (worker_threads), WASM"}},"/principles/concurrency-models":{"title":"Principles: Concurrency Models","data":{"":"SP8D supports all major cross-thread concurrency patterns out of the box, so you can pick the right one for your workload—from ultra-low-latency pipelines to scalable, many-agent systems.","quick-reference-table#Quick Reference Table":"Use this table to quickly match your concurrency needs to the right SP8D\nchannel model.\nModel\t# Producers\t# Consumers\tTypical Use Case\tSPSC\t1\t1\tSensor → Processor, UI event, SISO\tMPSC\tN\t1\tMany workers → main aggregator\tMPMC\tN\tM\tMulti-agent, load-balancing, simulation","single-producer-single-consumer-spsc#Single-Producer, Single-Consumer (SPSC)":"SPSC is the simplest and fastest concurrency model—ideal for direct,\none-to-one data flows where throughput and minimal contention are critical.\nDiagram: One producer, one consumer. Highest throughput,\nminimal contention.","key-points#Key Points":"Highest throughput, minimal contention.\nZero ambiguity: slots always move forward linearly.\nGreat for: video/audio pipelines, UI events, one-off data flows.\nSPSC is not ideal for fan-in or fan-out scenarios. Use MPSC or MPMC for\nthose patterns.","how-to-use#How to use":"const { channel } = createChannel({ mode: \"SPSC\" });\nSee the SPSC Example →\nLooking for installation or setup? See Quickstart: Installation →","multi-producer-single-consumer-mpsc#Multi-Producer, Single-Consumer (MPSC)":"MPSC lets you aggregate work from many sources into a single target—perfect\nfor logging, worker pools, or parallel data collection.\nDiagram: Multiple producers, one consumer. Good for parallel\ndata collection, AI tasks fanning in, worker pool → main thread.","key-points-1#Key Points":"Multiple producers, single sink.\nProducers contend for slots — SP8D’s segments reduce collisions.\nGood for: parallel data collection, AI tasks fanning in to model, worker pool → main thread.\nMPSC is not ideal for multi-consumer or mesh scenarios. Use MPMC for those\npatterns.","how-to-use-1#How to use":"const { channel } = createChannel({ mode: \"MPSC\", segments: 2 });\nNeed a minimal working code sample? See Quickstart: Minimal Example →","multi-producer-multi-consumer-mpmc#Multi-Producer, Multi-Consumer (MPMC)":"MPMC is the most flexible model, supporting many producers and many\nconsumers—ideal for load-balancing, multi-agent systems, or simulations at\nscale.\nDiagram: Many producers, many consumers. True concurrent mesh\nfor multi-agent, load-balancing, or simulation workloads.","key-points-2#Key Points":"True concurrent mesh: many-in, many-out.\nPerfect for multi-agent AIs, trading engines, any \"work distributed among many actors.\"\nSegmentation is critical for high contention/low latency.\nMPMC is not ideal for simple point-to-point or single-sink scenarios. Use\nSPSC or MPSC for those patterns.","how-to-use-2#How to use":"const { channel } = createChannel({ mode: \"MPMC\", segments: 4 });\nWant real-world integration code? See Quickstart: Common Recipes →","how-to-choose#How to Choose?":"Unsure which model to use? Match your use case to the recommended model below.\nYour Need:\tRecommended Model\tPoint-to-point data\tSPSC\tFan-in (best for logging, etc)\tMPSC\tMulti-agent, load balancing\tMPMC\t\nSegmentation reduces contention and enables scaling—set\nsegments > 1 for multiple producers or consumers. Map each\nproducerId or consumerId to a segment to further\nreduce slot collisions.","interop--scaling#Interop & Scaling":"Segmentation reduces contention and enables scaling—set segments > 1 for multiple producers or consumers. Map each producerId or consumerId to a segment to further reduce slot collisions.See segmentation deep-dive →\nLooking for protocol internals or slot state machine details? See Slot State Machine →","code-patterns-in-practice#Code Patterns in Practice":"Choose the right model for your architecture:\nSingle-thread to worker: SPSC\nSeveral AI inferences → UI: MPSC\nMarket sim, multi-copilot: MPMC\nSee integration recipes →"}},"/quickstart/common-recipes":{"title":"Quickstart: Common Recipes","data":{"":"Unlock SP8D’s superpowers: copy-paste these patterns to integrate channels across workers, threads, AI loops, and dashboards. Each recipe below is ready to use and includes a visual or explanation to help you understand the data flow and integration points.","in-a-browser-main-thread-to-worker#In a Browser (Main Thread to Worker)":"This pattern enables high-performance, zero-copy communication between your main thread and a Web Worker.\nRequires SharedArrayBuffer support in your browser.\nThe main thread creates the channel and buffer, transfers it to the worker,\nand both communicate through the shared channel.\nimport { createChannel } from \"@sp8d/core\";\nconst { channel, buffer } = createChannel({ slots: 16, slotSize: 32 });\nconst worker = new Worker(\"worker.js\");\nworker.postMessage(buffer, [buffer]);\nchannel.send(new Uint8Array([99, 100, 101]));\nimport { attachChannel } from \"@sp8d/core\";\nself.onmessage = (e: MessageEvent<SharedArrayBuffer>) => {\n  const channel = attachChannel(e.data);\n  const msg = channel.recv();\n  console.log(\"Worker received:\", msg); // Uint8Array([99, 100, 101])\n};","nodejs-with-worker_threads#Node.js with worker_threads":"This recipe shows how to use SP8D for fast, lock-free communication between Node.js worker threads.\nRequires Node.js 18+ and worker_threads.\nThe main thread creates the channel and buffer, passes it to the worker, and\nboth communicate through the shared channel.\nimport { createChannel } from \"@sp8d/core\";\nimport { Worker } from \"worker_threads\";\nconst { channel, buffer } = createChannel({ slots: 32, slotSize: 32 });\nconst worker = new Worker(\"./worker.js\", { workerData: buffer });\nchannel.send(new Uint8Array([123]));\nimport { workerData } from \"worker_threads\";\nimport { attachChannel } from \"@sp8d/core\";\nconst channel = attachChannel(workerData);\nconst msg = channel.recv();\nconsole.log(\"Worker received:\", msg); // Uint8Array([123])","multiplexing-multiple-producers-one-or-many-consumers#Multiplexing: Multiple Producers, One or Many Consumers":"This pattern enables scalable, concurrent communication by using segments or multiple channels. Each producer/consumer pair can be in its own worker.\nEach producer and consumer can operate in its own thread or worker, mapped to\nsegments for fair sharing and reduced contention.\n// In each producer thread:\nchannel.send(new Uint8Array([myProducerId]));\n// In each consumer thread:\nwhile (true) {\n  const msg = channel.recv();\n  if (msg) process(msg);\n}\nFor fair sharing and less contention, map producer/consumer IDs to segments\nusing (id % segments) when creating the channel.","integrating-with-ml-or-ai-model-workers#Integrating with ML or AI Model Workers":"This recipe demonstrates how to use SP8D for efficient, async message passing to and from ML/AI model workers.\nReplace runMyMLModel with your own model inference function.\nThe main thread sends data to the worker, which processes it (e.g., with an ML\nmodel) and can optionally send results back.\nimport { attachChannel } from \"@sp8d/core\";\nlet channel;\nself.onmessage = (e) => {\n  channel = attachChannel(e.data);\n};\nasync function processMessages() {\n  while (true) {\n    const msg = await channel.recvAsync(); // waits for a message\n    const result = await runMyMLModel(msg); // user-defined\n    // Optionally, send result back via another channel\n  }\n}\nprocessMessages();","using-diagnostics--stats#Using Diagnostics & Stats":"Monitor health and performance in real time with SP8D diagnostics.\nimport { createChannel, createChannelDiagnostics } from \"@sp8d/core\";\nconst { channel } = createChannel({ slots: 16, slotSize: 64 });\nconst diagnostics = createChannelDiagnostics(channel, 100);\ndiagnostics.onUpdate((stats) => {\n  console.log(\"SP8D Stats:\", stats);\n});\ndiagnostics.start();\nStats include: .used (msgs in flight), .throughput\n(msgs/sec), .consumerLag, .errors,\n.conflicts, .reclaimed.","handling-backpressure-full-buffer#Handling Backpressure (Full Buffer)":"This pattern shows how to handle cases where the buffer is full and the producer must wait or retry.\nIf the buffer is full, the producer must wait, retry, or drop messages as\nappropriate for your workload.\n// Producer waits if buffer is full\nconst payload = createPayload();\nwhile (!channel.send(payload)) {\n  // Buffer is full, wait a bit or drop/log as needed\n  await new Promise((r) => setTimeout(r, 1));\n}","next-steps#Next Steps":"Explore the API reference, diagnostics, and advanced usage guides for deeper\nintegration and troubleshooting.\nCore API Reference →\nDiagnostics and Live Dashboard Overlay →\nFAQ: “How do I broadcast? What about MPMC?” →\nHave a recipe to share or a tricky integration question? Open an Issue or Suggest Edits →"}},"/quickstart/installation":{"title":"Quickstart: Installation","data":{"":"Welcome to SP8D—the fastest, most reliable way to move data between threads and agents in your app. This guide will help you get SP8D running in your project quickly and correctly, with clear requirements and installation steps.","requirements#Requirements":"Before installing, ensure your environment meets the following requirements. SP8D is designed for modern JavaScript runtimes and does not require any native or C++ dependencies.\nNode.js 18+ or any modern browser supporting SharedArrayBuffer and Atomics.\nBrowser compatibility table →\nIn browsers, cross-origin headers may be required for SharedArrayBuffer.\nOnly modern browsers and Node.js 18+ are recommended for SP8D.","quickstart-install-sp8d#Quickstart: Install SP8D":"SP8D can be installed using NPM for production use, or loaded via CDN for prototyping and browser demos. The diagram below shows how SP8D integrates into your application stack.\nSP8D installation and integration flow: install via NPM for production, or\nimport from CDN for rapid prototyping.","npm-recommended#NPM (Recommended)":"To add SP8D to your project as a dependency, run:\nnpm install @sp8d/core","cdnunpkg-for-prototyping#CDN/Unpkg (For Prototyping)":"For quick browser demos or prototyping, you can import SP8D directly from a CDN:\n<script type=\"module\">\n  import {createChannel} from 'https://unpkg.com/@sp8d/core?module';\n</script>","commonjs#CommonJS":"If you are using CommonJS modules (e.g., in older Node.js projects):\nconst { createChannel } = require(\"@sp8d/core\");\nExample package.json\n{\n  \"name\": \"my-sp8d-app\",\n  \"type\": \"module\",\n  \"dependencies\": {\n    \"@sp8d/core\": \"^x.y.z\"\n  }\n}","typescript-support#TypeScript Support":"SP8D is written in TypeScript and ships with complete type definitions. No\nadditional type packages are required.\nSP8D is written in TypeScript and ships with complete type definitions. No additional type packages are required. This ensures seamless integration and type safety in TypeScript projects.For a minimal TypeScript example, see: Quickstart: Minimal Example →","smoke-test-verify-your-installation#Smoke Test: Verify Your Installation":"After installation, run this code to verify SP8D is working in your project.\nAfter installation, you can quickly verify that SP8D is working as expected by running the following code in your project:\nimport { createChannel } from \"@sp8d/core\";\nconst { channel } = createChannel({ slots: 4, slotSize: 64 });\nconsole.log(channel.info()); // Prints protocol details\nFor a more detailed walkthrough, see the Quickstart: Minimal Example → or consult the API Reference →.","next-steps#Next Steps":"Once SP8D is installed, follow the minimal example, explore common recipes, or\nlearn about debugging and concurrency models.\nOnce SP8D is installed, you can:\nFollow the Quickstart: Minimal Example →\nExplore Common Recipes: Browser Workers, Node.js, and More →\nLearn about Debugging & Diagnostics →\nUnderstand Concurrency Models →","troubleshooting#Troubleshooting":"If you encounter issues during installation or usage, consider the following.\n“Cannot use SharedArrayBuffer”: Ensure you are in a secure context (https:// with COOP/COEP headers). See FAQ →\nType errors? Make sure you are using Node.js 18+ or a supported bundler.\nStill stuck? Open an issue →"}},"/quickstart/minimal-example":{"title":"Quickstart: Minimal Example","data":{"":"This is the fastest way to get a working SP8D channel in your app. For environment requirements, see\nInstallation Requirements →.","minimal-example-single-producer-single-consumer#Minimal Example: Single Producer, Single Consumer":"The following is the most basic usage: one producer and one consumer,\ncommunicating via a lock-free, bounded channel. For a more complete and\nproduction-ready SPSC example, see\nBasic SPSC Example.","nodejs-typescript#Node.js (TypeScript)":"import { createChannel } from \"@sp8d/core\";\nconst { channel } = createChannel({ slots: 8, slotSize: 64 });\nchannel.send(new Uint8Array([42, 17, 8]));\nconst received: Uint8Array | undefined = channel.recv();\nconsole.log(\"Received:\", received); // Uint8Array([42, 17, 8])\nIf you prefer plain JavaScript, you can use the same code without type\nannotations.","browser-main-thread-to-worker-typescript#Browser: Main Thread to Worker (TypeScript)":"SP8D works seamlessly in browsers, enabling high-performance communication\nbetween the main thread and workers. This example uses two files: one for the\nmain thread, one for the worker. Requires SharedArrayBuffer support in your\nbrowser.\nimport { createChannel } from \"@sp8d/core\";\nconst { channel, buffer } = createChannel({ slots: 8, slotSize: 8 });\nconst worker = new Worker(\"worker.js\");\nworker.postMessage(buffer, [buffer]); // Transfer the SharedArrayBuffer\n// Send a message from main\nchannel.send(new Uint8Array([1, 2, 3, 4, 5, 6, 7, 8]));\nimport { attachChannel } from \"@sp8d/core\";\nself.onmessage = (e: MessageEvent<SharedArrayBuffer>) => {\n  const channel = attachChannel(e.data);\n  const msg: Uint8Array | undefined = channel.recv();\n  console.log(\"Worker received:\", msg); // Should log: Uint8Array([1,2,3,4,5,6,7,8])\n};\nIn this setup, the main thread creates the channel and transfers the buffer to\nthe worker. Both sides can now send and receive messages with zero-copy\nefficiency.\nData flow in the browser minimal example: the main thread creates the channel\nand buffer, transfers it to the worker, and both communicate through the\nshared channel.","how-it-works#How It Works":"This section summarizes the minimal mechanics behind SP8D’s channel\noperations. For deeper details, see the relevant documentation sections.\ncreateChannel: Allocates a shared ring buffer of slots for your messages, with safety and backpressure.\nsend: Producer claims a slot, writes the payload, and marks it as ready.\nrecv: Consumer waits for a ready slot, reads the data, and frees it.\nAll transitions happen atomically—no locks, ever.","why-use-sp8d-for-minimal-messaging#Why Use SP8D for Minimal Messaging?":"No setup of queues, events, Promise chains, or bounce buffers. Immediate\ndelivery, guaranteed boundedness, lock-free performance. No external\ndependencies beyond modern JS runtime support. Use channel.info()\nor channel.stats() to verify state and health.","try-live#Try Live":"Test SP8D channels interactively in your browser. A live harness is available for experimentation and diagnostics. Open the SP8D Harness →","where-to-next#Where To Next?":"Quickstart: Minimal Example →\nQuickstart: Common Integration Patterns →\nDiagnostics and State Overlays →\nCore API Reference →\nFAQ →\nOpen an Issue →"}}}